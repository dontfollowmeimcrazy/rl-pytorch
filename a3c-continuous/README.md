# Asynchronous Advantage Actor-Critc (A3C) implementation for continuous action RL tasks

Based on the paper Asynchronous Methods for Deep Reinforcement Learning [(link)](https://arxiv.org/abs/1602.01783) by Minh et al. You could use Generalized Advantage Estimation [(link)](https://arxiv.org/abs/1506.02438) to get better results.

Uses the OpenAI gym's environment `LunarLanderContinuous-v2`. 

Model implementations include a MLP and a LSTM.

Use python 3.

Inspired by https://github.com/dgriff777/a3c_continuous .